export type ReferenceInputKind = "reference-image" | "first-frame" | "last-frame" | "reference-video"

export type FalStudioModel = {
  id: string
  name: string
  description: string
  type: "image" | "video"
  provider: "fal"
  creator: string
  quality?: string
  supportsImageInput?: boolean
  supportsVideoInput?: boolean
  requiresReferenceImage?: boolean
  requiredInputs?: ReferenceInputKind[]
  optionalInputs?: ReferenceInputKind[]
}

export const FAL_MODEL_GROUPS: Array<{ creator: string; models: FalStudioModel[] }> = [
  {
    creator: "Black Forest Labs (FLUX)",
    models: [
      {
        id: "fal-ai/flux/dev",
        name: "FLUX.1 Dev",
        description: "High-quality general-purpose image generation",
        type: "image",
        quality: "High",
        provider: "fal",
        creator: "Black Forest Labs (FLUX)",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "fal-ai/flux/schnell",
        name: "FLUX.1 Schnell",
        description: "Fast FLUX variant for rapid iteration",
        type: "image",
        quality: "Balanced",
        provider: "fal",
        creator: "Black Forest Labs (FLUX)",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "fal-ai/flux/ultra",
        name: "FLUX.1 Ultra",
        description: "Maximum fidelity FLUX model tuned for detail",
        type: "image",
        quality: "Ultra",
        provider: "fal",
        creator: "Black Forest Labs (FLUX)",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "fal-ai/flux/realism",
        name: "FLUX Realism",
        description: "Photo-centric presets optimized for portraits",
        type: "image",
        quality: "Photoreal",
        provider: "fal",
        creator: "Black Forest Labs (FLUX)",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "fal-ai/fast-sdxl",
        name: "Fast SDXL",
        description: "Speed-optimized Stable Diffusion XL 1.0",
        type: "image",
        quality: "Balanced",
        provider: "fal",
        creator: "Black Forest Labs (FLUX)",
        requiredInputs: [],
        optionalInputs: [],
      },
    ],
  },
  {
    creator: "Google (Veo 3.1)",
    models: [
      {
        id: "veo3.1",
        name: "Veo 3.1",
        description: "Flagship text-to-video generation up to 1080p",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "Google (Veo 3.1)",
        requiredInputs: [],
        optionalInputs: ["reference-image"],
      },
      {
        id: "veo3.1/fast",
        name: "Veo 3.1 Fast",
        description: "Reduced latency text-to-video for rapid iteration",
        type: "video",
        quality: "Balanced",
        provider: "fal",
        creator: "Google (Veo 3.1)",
        requiredInputs: [],
        optionalInputs: ["reference-image"],
      },
      {
        id: "veo3.1/image-to-video",
        name: "Veo 3.1 Image-to-Video",
        description: "Animate a single reference image into cinematic motion",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "Google (Veo 3.1)",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "veo3.1/fast/image-to-video",
        name: "Veo 3.1 Fast Image-to-Video",
        description: "Low-latency image-to-video generation",
        type: "video",
        quality: "Balanced",
        provider: "fal",
        creator: "Google (Veo 3.1)",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "veo3.1/reference-to-video",
        name: "Veo 3.1 Reference-to-Video",
        description: "Guided video generation with style/character reference",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "Google (Veo 3.1)",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "veo3.1/fast/first-last-frame-to-video",
        name: "Veo 3.1 Fast First+Last Frame",
        description: "Rapid interpolation between first and last frame guides",
        type: "video",
        quality: "Balanced",
        provider: "fal",
        creator: "Google (Veo 3.1)",
        supportsImageInput: true,
        requiredInputs: ["first-frame", "last-frame"],
      },
      {
        id: "veo3.1/first-last-frame-to-video",
        name: "Veo 3.1 First+Last Frame",
        description: "Precise keyframe-controlled video generation",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "Google (Veo 3.1)",
        supportsImageInput: true,
        requiredInputs: ["first-frame", "last-frame"],
      },
    ],
  },
  {
    creator: "OpenAI (Sora 2)",
    models: [
      {
        id: "sora-2/text-to-video",
        name: "Sora 2 Text-to-Video",
        description: "OpenAI Sora 2 cinematic generation from text",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "OpenAI (Sora 2)",
        requiredInputs: [],
        optionalInputs: ["reference-image"],
      },
      {
        id: "sora-2/text-to-video/pro",
        name: "Sora 2 Text-to-Video Pro",
        description: "Extended controls and runtime for Sora 2 video",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "OpenAI (Sora 2)",
        requiredInputs: [],
        optionalInputs: ["reference-image"],
      },
      {
        id: "sora-2/image-to-video",
        name: "Sora 2 Image-to-Video",
        description: "Animate an image into a dynamic sequence",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "OpenAI (Sora 2)",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "sora-2/image-to-video/pro",
        name: "Sora 2 Image-to-Video Pro",
        description: "Higher fidelity image-to-video with pro controls",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "OpenAI (Sora 2)",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "sora-2/video-to-video/remix",
        name: "Sora 2 Video Remix",
        description: "Transform existing footage with Sora 2 stylisation",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "OpenAI (Sora 2)",
        supportsVideoInput: true,
        requiredInputs: ["reference-video"],
      },
    ],
  },
  {
    creator: "Runway",
    models: [
      {
        id: "fal-ai/runway-gen3/turbo",
        name: "Runway Gen-3 Turbo",
        description: "Text-to-video powerhouse for 5s cinematic clips",
        type: "video",
        quality: "High",
        provider: "fal",
        creator: "Runway",
        requiredInputs: [],
        optionalInputs: ["reference-image"],
      },
      {
        id: "fal-ai/runway-gen3/turbo/image-to-video",
        name: "Runway Gen-3 Turbo Image-to-Video",
        description: "Animate a still frame via Runway's Gen-3 Turbo",
        type: "video",
        quality: "High",
        provider: "fal",
        creator: "Runway",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
    ],
  },
  {
    creator: "Kling",
    models: [
      {
        id: "fal-ai/kling-video/v2.5-turbo/pro/image-to-video",
        name: "Kling v2.5 Turbo Pro Image-to-Video",
        description: "ByteDance Kling image-to-video with motion emphasis",
        type: "video",
        quality: "High",
        provider: "fal",
        creator: "Kling",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
    ],
  },
  {
    creator: "Mochi",
    models: [
      {
        id: "fal-ai/mochi/mochi-1",
        name: "Mochi 1",
        description: "Long-form video diffusion for storytelling",
        type: "video",
        quality: "Cinematic",
        provider: "fal",
        creator: "Mochi",
        requiredInputs: [],
        optionalInputs: ["reference-image"],
      },
    ],
  },
  {
    creator: "fal.ai Latest Releases",
    models: [
      {
        id: "bria-fibo",
        name: "BRIA Fibo",
        description: "BRIA's Fibo generator for expressive visual stories",
        type: "video",
        provider: "fal",
        creator: "BRIA",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "veo-3.1",
        name: "Veo 3.1",
        description: "Google Veo 3.1 cinematic text-to-video",
        type: "video",
        quality: "Ultra",
        provider: "fal",
        creator: "Google",
        requiredInputs: [],
        optionalInputs: ["reference-image"],
      },
      {
        id: "kling-video/v2.5-turbo/pro/image-to-video",
        name: "Kling v2.5 Turbo Pro",
        description: "ByteDance Kling high-detail image-to-video",
        type: "video",
        quality: "High",
        provider: "fal",
        creator: "ByteDance",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "wan-2.5-image-to-video",
        name: "WAN 2.5 Image-to-Video",
        description: "WAN 2.5 animation from reference imagery",
        type: "video",
        provider: "fal",
        creator: "WavJourney",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "nano-banana",
        name: "Nano Banana",
        description: "Lightweight creative video generator",
        type: "video",
        provider: "fal",
        creator: "fal.ai",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "longcat-video-distilled",
        name: "Longcat Video Distilled",
        description: "Longcat distilled model for extended video scenes",
        type: "video",
        provider: "fal",
        creator: "fal.ai",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "minimax/hailuo-2.3/pro/image-to-video",
        name: "MiniMax Hailuo 2.3 Pro",
        description: "MiniMax Hailuo pro image-to-video",
        type: "video",
        provider: "fal",
        creator: "MiniMax",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "minimax/hailuo-2.3/fast-image-to-video",
        name: "MiniMax Hailuo 2.3 Fast",
        description: "Faster MiniMax Hailuo image-to-video",
        type: "video",
        provider: "fal",
        creator: "MiniMax",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "minimax/hailuo-2.3/text-to-video",
        name: "MiniMax Hailuo 2.3 Text-to-Video",
        description: "Text-to-video pipeline from MiniMax Hailuo",
        type: "video",
        provider: "fal",
        creator: "MiniMax",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "reve-edit",
        name: "Reve Edit",
        description: "Reve Edit creative video editing diffusion",
        type: "video",
        provider: "fal",
        creator: "Reve",
        supportsVideoInput: true,
        requiredInputs: ["reference-video"],
        optionalInputs: [],
      },
      {
        id: "flux-kontext-lora/image-to-image",
        name: "FLUX Kontext LoRA Image-to-Image",
        description: "FLUX Kontext LoRA guided image-to-image",
        type: "image",
        provider: "fal",
        creator: "Black Forest Labs",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "flux-kontext-lora/text-to-image",
        name: "FLUX Kontext LoRA Text-to-Image",
        description: "Text-to-image with Kontext LoRA styling",
        type: "image",
        provider: "fal",
        creator: "Black Forest Labs",
        requiredInputs: [],
        optionalInputs: [],
      },
      {
        id: "sora-2-image-to-video",
        name: "Sora 2 Image-to-Video",
        description: "Sora 2 animation from still imagery",
        type: "video",
        provider: "fal",
        creator: "OpenAI",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "sora-2-text-to-video",
        name: "Sora 2 Text-to-Video",
        description: "Sora 2 cinematic text-to-video generation",
        type: "video",
        provider: "fal",
        creator: "OpenAI",
        requiredInputs: [],
        optionalInputs: ["reference-image"],
      },
      {
        id: "sora-2-video-to-video-remix",
        name: "Sora 2 Video Remix",
        description: "Remix existing footage with Sora 2",
        type: "video",
        provider: "fal",
        creator: "OpenAI",
        supportsVideoInput: true,
        requiredInputs: ["reference-video"],
      },
      {
        id: "pixverse/v5/image-to-video",
        name: "PixVerse v5 Image-to-Video",
        description: "PixVerse v5 animated image-to-video",
        type: "video",
        provider: "fal",
        creator: "PixVerse",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "fal-ai/wan/v2.2-A14B/image-to-video",
        name: "WAN v2.2 A14B Image-to-Video",
        description: "WAN v2.2 large model for image animation",
        type: "video",
        provider: "fal",
        creator: "fal.ai",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "ltxv-13b-098-distilled/image-to-video",
        name: "LTXV 13B Distilled Image-to-Video",
        description: "Distilled LTXV 13B for image driven video",
        type: "video",
        provider: "fal",
        creator: "LTXV",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "creatify/lipsync",
        name: "Creatify Lipsync",
        description: "Creatify lipsync animation from reference video",
        type: "video",
        provider: "fal",
        creator: "Creatify",
        supportsVideoInput: true,
        requiredInputs: ["reference-video"],
      },
      {
        id: "bytedance/omnihuman/v1.5/image-to-video",
        name: "OmniHuman v1.5 Image-to-Video",
        description: "ByteDance OmniHuman character animation",
        type: "video",
        provider: "fal",
        creator: "ByteDance",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "minimax/lipsync",
        name: "MiniMax Lipsync",
        description: "MiniMax lipsync diffusion for talking avatars",
        type: "video",
        provider: "fal",
        creator: "MiniMax",
        supportsVideoInput: true,
        requiredInputs: ["reference-video"],
      },
      {
        id: "pixverse/lipsync",
        name: "PixVerse Lipsync",
        description: "PixVerse lipsync for expressive avatars",
        type: "video",
        provider: "fal",
        creator: "PixVerse",
        supportsVideoInput: true,
        requiredInputs: ["reference-video"],
      },
      {
        id: "flux-kontext-lora/inpaint",
        name: "FLUX Kontext LoRA Inpaint",
        description: "Image inpainting with Kontext LoRA",
        type: "image",
        provider: "fal",
        creator: "Black Forest Labs",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
      {
        id: "flux-pro/kontext/image-to-image",
        name: "FLUX Pro Kontext Image-to-Image",
        description: "FLUX Pro Kontext guided image transformation",
        type: "image",
        provider: "fal",
        creator: "Black Forest Labs",
        supportsImageInput: true,
        requiresReferenceImage: true,
        requiredInputs: ["reference-image"],
      },
    ],
  },
]

export const ALL_FAL_MODELS: FalStudioModel[] = FAL_MODEL_GROUPS.flatMap((group) => group.models)
